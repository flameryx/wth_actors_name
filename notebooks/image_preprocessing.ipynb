{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "judicial-motivation",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coated-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder, number_of_images):\n",
    "    images = []\n",
    "    \n",
    "    counter = 0\n",
    "    #fraction is the fraction of the total image dataset to be loaded\n",
    "    \n",
    "    \n",
    "    #iterating through the image files in the folder\n",
    "    for image_number in range(len(os.listdir(folder))):\n",
    "            \n",
    "        if counter < int(number_of_images*1.5):\n",
    "            \n",
    "            filename = str(image_number) + \".jpg\"\n",
    "        \n",
    "            # loading the image in greyscale\n",
    "            img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "            #if image with correct filename was found then append to image list\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                \n",
    "\n",
    "                \n",
    "                counter += 1\n",
    "            \n",
    "    return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mental-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reverse-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    \n",
    "    #setting the cascade classifier\n",
    "    rectangle = face_cascade.detectMultiScale(img, scaleFactor = 1.1, minNeighbors = 4)\n",
    "    \n",
    "    #if no face is found the\n",
    "    if len(rectangle) == 0:\n",
    "        return None\n",
    "\n",
    "    #setting the right coordinates\n",
    "    rectangle[:,2:] += rectangle[:,:2]\n",
    "    \n",
    "    return rectangle[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "optical-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_images(origin_folder,cropped_folder, number_of_images):\n",
    "    \n",
    "    #loading images\n",
    "    image_list = load_images_from_folder(origin_folder, number_of_images)\n",
    "    \n",
    "    #set output image dimensions\n",
    "    dim = (100,100)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(image_list)):\n",
    "        \n",
    "        #calcultating coordinates of face\n",
    "        coordinates = detect_face(image_list[i])\n",
    "        \n",
    "        \n",
    "        #if the detect face function found a face then proceed\n",
    "        if coordinates is not None:\n",
    "            \n",
    "            if counter < number_of_images:\n",
    "            \n",
    "                counter += 1\n",
    "        \n",
    "                #unpacking coordinates\n",
    "                x1, y1, x2, y2 = coordinates\n",
    "            \n",
    "                #cropping and resizing the image\n",
    "                resized_image = cv2.resize(image_list[i][y1:y2,x1:x2], dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "                #saving to cropped_folder\n",
    "                cv2.imwrite(os.path.join(cropped_folder, str(i) + \".jpg\"), resized_image)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amateur-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is essential os.listdir without showing hidden files\n",
    "\n",
    "import glob\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_folder_preprocessing(origin, destination, number_of_images = 20):\n",
    "\n",
    "    folders_in_origin = listdir_nohidden(origin)\n",
    "\n",
    "    #iterate over the names of the actors in the main folder:\n",
    "    for actor_name in folders_in_origin:\n",
    "            \n",
    "        #only select last part of the filepath in folders_in_origin which is the actor name\n",
    "        actor_name = os.path.basename(os.path.normpath(actor_name))\n",
    "            \n",
    "        #create a new subfolder named after the actor\n",
    "        os.mkdir(os.path.join(destination, actor_name))\n",
    "    \n",
    "        #save path of the subfolder\n",
    "        destination_subfolder = os.path.join(destination,actor_name)\n",
    "    \n",
    "        #preprocess images for one actor and save them too destination subfolder\n",
    "        save_preprocessed_images(os.path.join(origin,actor_name), destination_subfolder, number_of_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-drama",
   "metadata": {},
   "source": [
    "## Running Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-hometown",
   "metadata": {},
   "source": [
    "running test for individual folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automatic-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_preprocessed_images(\"/Users/elias/Desktop/actors/Adriana Lima\",destination, number_of_images = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-haven",
   "metadata": {},
   "source": [
    "running test for multiple folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assumed-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = \"/Users/elias/Desktop/preprocessed test images\"\n",
    "\n",
    "origin = \"/Users/elias/Desktop/hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "terminal-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_folder_preprocessing(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-marketing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-still",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-shepherd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
