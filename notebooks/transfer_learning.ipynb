{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attempted-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "operating-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sexual-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 100\n",
    "img_cols = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "annual-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG = VGG16(weights = \"imagenet\",\n",
    "           include_top = False,\n",
    "           input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spectacular-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in VGG.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flexible-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "for (i,layer) in enumerate(VGG.layers):\n",
    "    print(str(i) + \" \" + layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smoking-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "#from tensorflow.keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powerful-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(bottom_model, num_classes):\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(512, activation = \"relu\")(top_model)\n",
    "    top_model = Dense(512, activation = \"relu\")(top_model)\n",
    "    top_model = Dense(256, activation = \"relu\")(top_model)\n",
    "    top_model = Dense(num_classes, activation = \"softmax\")(top_model)\n",
    "    \n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decreased-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top = new_model(VGG, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polyphonic-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Model(inputs = VGG.input, outputs = model_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "annoying-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 15,376,468\n",
      "Trainable params: 661,780\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "advance-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hundred-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "infectious-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/elias/Desktop/destination_color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "structural-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 45,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    validation_split = 0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "assured-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "substantial-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "loaded_train_data = data_generator.flow_from_directory(\n",
    "    directory,\n",
    "    target_size = (img_rows,img_cols),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"categorical\",\n",
    "    subset='training'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "mysterious-colonial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "loaded_val_data = data_generator.flow_from_directory(\n",
    "    directory,\n",
    "    target_size = (img_rows,img_cols),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"categorical\",\n",
    "    subset='validation'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-triple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-sample",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-yesterday",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-boring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-burns",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "severe-stewart",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-f7d283d518a2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-f7d283d518a2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    loaded_data.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "decreased-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "confirmed-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=10, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "simplified-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "appropriate-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRreducer = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.1, patience=3, verbose=1, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "simple-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStopper = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "focused-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    }
   ],
   "source": [
    "TensorBoard = keras.callbacks.TensorBoard(log_dir=\"log/{}\".format(final_model), histogram_freq=0, batch_size=32, write_graph=True, write_grads=True, write_images=True, update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "moved-coupon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "50/50 [==============================] - 85s 2s/step - loss: 2.7456 - accuracy: 0.1462 - val_loss: 2.5805 - val_accuracy: 0.1625\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 89s 2s/step - loss: 2.5120 - accuracy: 0.2125 - val_loss: 2.3360 - val_accuracy: 0.3100\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 91s 2s/step - loss: 2.3472 - accuracy: 0.2844 - val_loss: 2.3259 - val_accuracy: 0.2825\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 86s 2s/step - loss: 2.3086 - accuracy: 0.2756 - val_loss: 2.1306 - val_accuracy: 0.3525\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 85s 2s/step - loss: 2.1867 - accuracy: 0.3325 - val_loss: 1.9497 - val_accuracy: 0.3825\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 97s 2s/step - loss: 2.1109 - accuracy: 0.3487 - val_loss: 2.0084 - val_accuracy: 0.3825\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 100s 2s/step - loss: 2.0763 - accuracy: 0.3706 - val_loss: 1.9592 - val_accuracy: 0.4400\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 81s 2s/step - loss: 1.9561 - accuracy: 0.4144 - val_loss: 1.9007 - val_accuracy: 0.4125\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 1.9334 - accuracy: 0.4212 - val_loss: 1.8156 - val_accuracy: 0.4650\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 86s 2s/step - loss: 1.9123 - accuracy: 0.4281 - val_loss: 1.8490 - val_accuracy: 0.4650\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 89s 2s/step - loss: 1.8237 - accuracy: 0.4481 - val_loss: 1.8287 - val_accuracy: 0.4625\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 87s 2s/step - loss: 1.8185 - accuracy: 0.4494 - val_loss: 1.7233 - val_accuracy: 0.4875\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 85s 2s/step - loss: 1.7623 - accuracy: 0.4712 - val_loss: 1.7369 - val_accuracy: 0.4750\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 91s 2s/step - loss: 1.7137 - accuracy: 0.4712 - val_loss: 1.6841 - val_accuracy: 0.4550\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 93s 2s/step - loss: 1.6908 - accuracy: 0.4812 - val_loss: 1.7857 - val_accuracy: 0.4625\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 93s 2s/step - loss: 1.6588 - accuracy: 0.4963 - val_loss: 1.7062 - val_accuracy: 0.4750\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 93s 2s/step - loss: 1.6358 - accuracy: 0.5269 - val_loss: 1.7464 - val_accuracy: 0.4925\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 1.5142 - accuracy: 0.5362 - val_loss: 1.6571 - val_accuracy: 0.5100\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 91s 2s/step - loss: 1.4754 - accuracy: 0.5569 - val_loss: 1.5531 - val_accuracy: 0.5200\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 91s 2s/step - loss: 1.4351 - accuracy: 0.5606 - val_loss: 1.5162 - val_accuracy: 0.5675\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 96s 2s/step - loss: 1.4160 - accuracy: 0.5738 - val_loss: 1.5350 - val_accuracy: 0.5550\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 84s 2s/step - loss: 1.4325 - accuracy: 0.5681 - val_loss: 1.5434 - val_accuracy: 0.5425\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 83s 2s/step - loss: 1.4037 - accuracy: 0.5594 - val_loss: 1.5915 - val_accuracy: 0.4975\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 71s 1s/step - loss: 1.4154 - accuracy: 0.5569 - val_loss: 1.4760 - val_accuracy: 0.5400\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 72s 1s/step - loss: 1.3705 - accuracy: 0.5806 - val_loss: 1.4914 - val_accuracy: 0.5175\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 76s 2s/step - loss: 1.4073 - accuracy: 0.5681 - val_loss: 1.5424 - val_accuracy: 0.5300\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 1.3817 - accuracy: 0.5656 - val_loss: 1.5191 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 72s 1s/step - loss: 1.3779 - accuracy: 0.5831 - val_loss: 1.4860 - val_accuracy: 0.5575\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 1.4101 - accuracy: 0.5675 - val_loss: 1.5112 - val_accuracy: 0.5200\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 69s 1s/step - loss: 1.3832 - accuracy: 0.5713 - val_loss: 1.5731 - val_accuracy: 0.5400\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 70s 1s/step - loss: 1.3609 - accuracy: 0.5800 - val_loss: 1.5745 - val_accuracy: 0.5350\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 70s 1s/step - loss: 1.3766 - accuracy: 0.5750 - val_loss: 1.5459 - val_accuracy: 0.5300\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 70s 1s/step - loss: 1.3770 - accuracy: 0.5831 - val_loss: 1.5385 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 1.3643 - accuracy: 0.5775 - val_loss: 1.4683 - val_accuracy: 0.5875\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 71s 1s/step - loss: 1.3778 - accuracy: 0.5888 - val_loss: 1.5012 - val_accuracy: 0.5625\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 69s 1s/step - loss: 1.3779 - accuracy: 0.5744 - val_loss: 1.4786 - val_accuracy: 0.5550\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 1.3682 - accuracy: 0.5756 - val_loss: 1.5175 - val_accuracy: 0.5575\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 79s 2s/step - loss: 1.3795 - accuracy: 0.5769 - val_loss: 1.5700 - val_accuracy: 0.5525\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 77s 2s/step - loss: 1.4156 - accuracy: 0.5638 - val_loss: 1.5770 - val_accuracy: 0.5400\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 1.3749 - accuracy: 0.5781 - val_loss: 1.5654 - val_accuracy: 0.5225\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(loaded_train_data,\n",
    "                    steps_per_epoch=1600/batch_size,\n",
    "                    epochs=40,\n",
    "                    callbacks = [LRreducer, EarlyStopper, TensorBoard],\n",
    "                    validation_data = loaded_val_data,\n",
    "                    validation_steps = 400/batch_size\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "medium-terminal",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-c3d6447f6ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "history.epoch[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-railway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-combine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-montana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-advice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
